 ## Data preparation 
 Vine dataset is downloaded from https://acmmm16.wixsite.com/mm16  
 YUP++ dataset is downloaded from http://vision.eecs.yorku.ca/research/dynamic-scenes/
 
 ## Feature Extraction  
 We use the codes provided by https://github.com/antoine77340/video_feature_extractor to extract content feature maps and motion features.
 
 ## HA-TSFN  
 Our model is implemented by Tensorflow1.4 and Python2.7

 ## 4. Reference 
 If you are interested in our work and want to cite it, please acknowledge the following paper:  
  ```
  @article{Zhang-HATSFN-TMM2020,  
    title={Hybrid-Attention Enhanced Two-Stream Fusion Network for Video Venue Prediction},  
    author={Yanchao Zhang, and Weiqing Min, and Liqiang Nie, and Shuqiang Jiang},  
    journal={IEEE Transactions on Multimedia (Accepted)},  
    year={2020}  
    } 
  ```
